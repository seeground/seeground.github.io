<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="SeeGround: See and Ground for Zero-Shot Open-Vocabulary 3D Visual Grounding.">
  <meta name="keywords" content="Zero Shot, Open Vocabulary, 3D Visual Grounding, VLM">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SeeGround - Project Page</title>

  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Nunito" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <!-- <link rel="stylesheet" href="./static/css/bulma-carousel.min.css"> -->
  <!-- <link rel="stylesheet" href="./static/css/bulma-slider.min.css"> -->
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <!-- <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script> -->
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <!-- <script src="./static/js/bulma-carousel.min.js"></script> -->
  <!-- <script src="./static/js/bulma-slider.min.js"></script> -->
  <!-- <script src="./static/js/index.js"></script> -->


  <!-- point cloud 的 JavaScript 文件 -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/loaders/PLYLoader.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/controls/OrbitControls.js"></script>

  <!-- 引用点云的脚本 -->
  <script defer src="./point_cloud.js"></script>
  <script defer src="./query-aligned-img.js"></script>


  <style>
    .a {
      color: rgb(1, 177, 160);
    }

    .query-container {
      padding: 10px;
    }

    .query-item {
      display: flex;
      align-items: center;
      width: 100%;
      margin-bottom: 10px;
      padding: 10px;
      background-color: white;
      color: black;
      border: 1px solid #ccc;
      border-radius: 10px;
      cursor: pointer;
      text-align: left;
      font-size: 16px;
    }

    .query-item:hover {
      background-color: #f0f0f0;
    }

    .query-dot {
      display: inline-block;
      width: 15px;
      height: 15px;
      margin-right: 10px;
      border: 2px solid black;
      border-radius: 50%;
    }

    .query-item.active .query-dot {
      background-color: rgb(1, 177, 160);
      border: 2px solid black;
    }

    .columns {
      display: flex;
      justify-content: flex-start;
      padding: 5px;
      text-align: left;
    }

    .tag {
      background-color: #f5f5f5;
      border-radius: 3px;
      padding: 5px;
      margin-right: 5px;
      font-size: 14px;
      color: #333;
    }
  </style>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <img src="./seeground/logo-seeground.png" style="width: 200px; margin-bottom: 50px;">
            <h1 class="title is-1 publication-title">
              <span style="color: #FF8E26;"><b>See</b></span><span style="color: #01B1A0;"><b>Ground</b></span>: See and Ground for Zero-Shot Open-Vocabulary 3D Visual
              Grounding
            </h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://rongli.tech/"><strong>Rong Li</strong></a><sup>1</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
              </span>
              <span class="author-block">
                <a href="https://sj-li.com/"><strong>Shijie Li</strong></a><sup>2</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
              </span>
              <span class="author-block">
                <a href="https://ldkong.com/"><strong>Lingdong Kong</strong></a><sup>3</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
              </span>
              <span class="author-block">
                <a href="https://dawdleryang.github.io/"><strong>Xulei Yang</strong></a><sup>2</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
              </span>
              <span class="author-block">
                <a href="https://junweiliang.me/"><strong>Junwei Liang</strong></a><sup>1,4,&#9993;</sup>
              </span>
            </div>

            <br/>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <sup>1</sup>AI Thrust, HKUST(Guangzhou)&nbsp;&nbsp;&nbsp;&nbsp;
              </span>
              <span class="author-block">
                <sup>2</sup>I2R, A*STAR&nbsp;&nbsp;&nbsp;&nbsp;
              </span>
              <span class="author-block">
                <sup>3</sup>National University of Singapore&nbsp;&nbsp;&nbsp;&nbsp;
              </span>
              <span class="author-block">
                <sup>4</sup>CSE, HKUST
              </span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2412.04383" target="_blank"
                      class="external-link button is-dark"
                      style="background-color: #01B1A0;  color: white; border-color: #01B1A0;">
                      <span class="icon"><i class="fas fa-file-pdf"></i></span>
                      <span><b>Paper</b></span>
                  </a>
                </span>

                &nbsp;
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2412.04383" target="_blank"
                      class="external-link button is-dark"
                      style="background-color: #01B1A0; color: white; border-color: #01B1A0;">
                      <span class="icon"><i class="fas fa-file-pdf"></i></span>
                      <span><b>arXiv</b></span>
                  </a>
                </span>

                <!-- Video Link. -->
                  <!-- <span class="link-block">
                  <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span> -->
                <!-- Code Link. -->

                &nbsp;
                <span class="link-block">
                  <a href="https://github.com/iris0329/SeeGround" target="_blank"
                      class="external-link button is-dark"
                      style="background-color: #01B1A0; color: white; border-color: #01B1A0;">
                      <span class="icon"><i class="fab fa-github"></i></span>
                      <span><b>Code</b></span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section" style="margin-top: -10px;">
    <div class="container is-max-desktop">

      <div class="columns is-centered">
        <div class="column is-full-width has-text-centered">
          <h2 class="title is-3">Abstract</h2>
          <img src="./static/images/teaser.png" />
          <div class="content has-text-justified" style="padding-top: 15px">
            <p>
              <b>3D Visual Grounding (3DVG)</b> aims to locate objects in 3D scenes based on textual
              descriptions, which is essential for applications like augmented reality and robotics.
              Traditional 3DVG approaches rely on annotated 3D datasets and predefined object categories, limiting
              scalability and adaptability.
              To overcome these limitations, we introduce <span style="color: #FF8E26;"><b>See</b></span><span
                style="color: #01B1A0;"><b>Ground</b></span>,
              a <b>zero-shot 3DVG framework</b> leveraging 2D Vision-Language Models (VLMs) trained on large-scale 2D data. We
              propose to represent 3D scenes as a hybrid of query-aligned rendered images and spatially enriched text
              descriptions, bridging the gap between 3D data and 2D-VLMs input formats. We propose <b>two modules</b>: the
              Perspective Adaptation Module, which dynamically selects viewpoints for query-relevant image rendering,
              and the Fusion Alignment Module, which integrates 2D images with 3D spatial descriptions to enhance object
              localization.
              Extensive experiments on ScanRefer and Nr3D demonstrate that our approach outperforms existing zero-shot
              methods by large margins.
              Notably, we exceed weakly supervised methods and rival some fully supervised ones,
              outperforming previous SOTA by 7.7% on ScanRefer and 7.1% on Nr3D, showcasing its effectiveness.
            </p>
          </div>
          <hr>
        </div>
      </div>
    </div>
  </section>



  <section class="section" style="margin-top: -50px;"></section>
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class=" column is-full-width has-text-centered">
        <h2 class="title is-3">
          <span class="icon"><i class="fa fa-paw"></i></span>&thinsp; The <span style="color: #FF8E26;"><b>See</b></span><span style="color: #01B1A0;"><b>Ground</b></span> Framework
        </h2>
      <img src="./static/images/arch_1.png" />
      <div class="content has-text-justified" style="padding-top: 15px">
        <p>
          <b>Figure.</b> Overview of the <span style="color: #FF8E26;"><b>See</b></span><span style="color: #01B1A0;"><b>Ground</b></span> framework. 
          We first use a 2D-VLM to interpret the query,
          identifying both the target object (e.g., "laptop") and a context-providing anchor (e.g., "chair with floral
          pattern"). A dynamic viewpoint is then selected based on the anchor’s position, enabling the capture of a 2D
          rendered image that aligns with the query’s spatial requirements. Using the Object Lookup Table (OLT), we
          retrieve the 3D bounding boxes of relevant objects, project them onto the 2D image, and apply visual prompts
          to mark visible objects, filtering out occlusions. The image with prompts, along with the spatial
          descriptions and query, are then input into the 2D-VLM for precise localization of the target object.
          Finally, the 2D-VLM outputs the target object’s ID, and we retrieve its 3D bounding box from the OLT to
          provide the final, accurate 3D position in the scene.
        </p>
      </div>
      <hr>
    </div>
  </div>
  </div>
  </section>



  <section class="section" style="margin-top: -50px;"></section>
    <div class="container is-max-desktop">
      <div class="columns is-centered" style="display: flex; align-items: center;">
        <!-- Left Column for the Image -->
        <div class="column is-half" style="text-align: center;">
          <img src="./static/images/perspective_selection.png" style="max-width: 100%; height: auto;" />
        </div>
        <!-- Right Column for the Text -->
        <div class="column is-half">
          <div class="content has-text-justified" style="padding-left: 15px;">
            <h2 class="title is-3">
              Perspective Selection
            </h2>
            <p>
              There are many strategies for rendering images from the 3D scene, for instance, LAR positions the camera around each object to capture multi-view images. 
              While this provides detailed views, it lacks overall scene context, making it difficult to interpret relationships between objects.
              Another is BEV, where the camera is positioned above the scene center, capturing a top-down perspective.
              Different from existing methods, our “Query-Aligned” strategy dynamically adapts the viewpoint to match the spatial context of the query, enhancing detail and relevance of visible objects compared to static methods.
            </p>
          </div>
        </div>
      </div><hr>
    </div>
  </section>


  <br/>


  <section class="section" style="margin-top: -50px;"></section>
    <div class="container is-max-desktop">
      <div class="columns is-centered" style="display: flex; align-items: center;">
        <!-- Left Column for the Text -->
        <div class="column is-half">
          <div class="content has-text-justified" style="padding-right: 15px;">
            <h2 class="title is-3">
              Visual Prompts
            </h2>
            <p>
              We provide an analysis of designs on visual prompts, including Mask, Contour, and BBOX.
              Each presents unique advantages and limitations, particularly when combined with 3D spatial information. 
              <br/>
              <b>Mask.</b> It intuitively highlights the entire object surface. However, even with high transparency, it can obscure surface details like texture and fine-grained patterns, which are critical for distinguishing objects.
              <br/>
              <b>BBOX.</b> It clearly defines boundaries but introduces visual complexity due to the overlay of bounding box lines. These lines often obscure surface features (colors or textures).
              <br/>
              <b>Marker.</b> It offers the most minimal and focused design, marking object centers without introducing visual clutter or occluding appearance features. 
              This maximally preserves object details like texture and color while providing essential spatial information.
            </p>
          </div>
        </div>
        <!-- Right Column for the Image -->
        <div class="column is-half" style="text-align: center;">
          <img src="./static/images/visual_prompts.png" style="max-width: 100%; height: auto;" />
        </div>
      </div><hr>
    </div>
  </section>


  <br/>



  <section class="section" style="margin-top: -50px;"></section>
    <div class="container is-max-desktop">
      <div class="columns is-centered" style="display: flex; align-items: center;">
        <!-- Left Column for the Image -->
        <div class="column is-half" style="text-align: center;">
          <img src="./static/images/robustness.png" style="max-width: 100%; height: auto;" />
        </div>
        <!-- Right Column for the Text -->
        <div class="column is-half">
          <div class="content has-text-justified" style="padding-left: 15px;">
            <h2 class="title is-3">
              Robustness under Incomplete Textual Description
            </h2>
            <p>
              We test the robustness of our approach with incomplete textual information, simulating common misdetection scenarios. 
              By omitting an anchor object from the text while retaining the target, our model uses visual cues to compensate, achieving accurate localization.
              In contrast, LLM performance degrades without the anchor.
              These results demonstrate that our method maintains high accuracy with partial text, underscoring the importance of integrating visual and textual data for reliable 3DVG.
            </p>
          </div>
        </div>
      </div><hr>
    </div>
  </section>


  <br/>



  <section class="section" style="margin-top: 20px;">
    <div class="container is-max-desktop">
      <!--/ Matting. -->

      <!-- Animation. -->
      <div class="columns is-centered">
        <div class="column is-full-width has-text-centered">
          <h2 class="title is-3">
            <span class="icon"><i class="fa fa-cogs"></i></span>&thinsp; Experiments
          </h2>
          <!-- Re-rendering. -->

          <h3 class="title is-4" style="margin-top: 50px;">Qualitative Results</h3>

          <div class="column is-full-width">

            <div class="columns is-centered" style="display: flex; justify-content: space-between; padding: 5px">
              <!-- 第一个视频及其介绍 -->
              <div style="flex: 1; margin-right: 10px; text-align: center;">
                <video poster="" autoplay="" controls="" muted="" loop=""
                  style="border-radius: 10px; border: 1px solid #ccc; width: 100%;">
                  <source src="./static/videos/video25.mp4" type="video/mp4">
                </video>
                <p>"It is the white keyboard, further from the door"</p>
              </div>
              <!-- 第二个视频及其介绍 -->
              <div style="flex: 1; margin-left: 10px; text-align: center;">
                <video poster="" autoplay="" controls="" muted="" loop=""
                  style="border-radius: 10px; border: 1px solid #ccc; width: 100%;">
                  <source src="./static/videos/video15.mp4" type="video/mp4">
                </video>
                <p>"Whiteboard with four chairs and desk in front of it"</p>
              </div>
            </div>

            <div class="content has-text-justified" style="padding-top: 1px">
              <!-- <p>Our method XXXXX.</p> -->
            </div>
            <div class="columns is-centered" style="display: flex; justify-content: space-between; padding: 5px">
              <!-- 第三个视频及其介绍 -->
              <div style="flex: 1; margin-right: 10px; text-align: center;">
                <video poster="" autoplay="" controls="" muted="" loop=""
                  style="border-radius: 10px; border: 1px solid #ccc; width: 100%;">
                  <source src="./static/videos/video30.mp4" type="video/mp4">
                </video>
                <p>"A red felt office chair with plastic wheels is positioned between a cream chair and a blue chair at
                  the desk furthest from the entrance, facing away from the door"</p>
              </div>
              <!-- 第四个视频及其介绍 -->
              <div style="flex: 1; margin-left: 10px; text-align: center;">
                <video poster="" autoplay="" controls="" muted="" loop=""
                  style="border-radius: 10px; border: 1px solid #ccc; width: 100%;">
                  <source src="./static/videos/video50.mp4" type="video/mp4">
                </video>
                <p>"There is a laptop on the desk in the corner of the room. The laptop is in front of a single person
                  brown leather armchair"</p>
              </div>
            </div>

            <hr>
          </div>

          <!-- 
-------------------------------------------------------------------------------------------------------- 
-->
          <div class="column is-full-width">
            <div class="content has-text-justified" style="margin-top: 50px;">
              <h3 class="title is-4">
                <span class="icon"><i class="fa fa-paper-plane"></i></span> Interactive Demo
              </h3>
              <!-- <div class="columns is-centered" style="display: flex; justify-content: space-between; padding: 5px"> -->
              <div class="content has-text-justified">
                <p>
                  Here, we presents an interactive 3D room visualization.
                  When a <b>query</b> is selected, the left panel displays an <b>interactive 3D scene</b> where the
                  target
                  object's <b>3D bounding box</b> is
                  highlighted. The right panel shows the <b>query-aligned 2D rendered image</b>. Users can interact
                  with the 3D scene in the left panel using the following controls:
                </p>
              </div>
              <!-- </div> -->

              <div class="columns" style="display: flex; justify-content: flex-start; padding: 5px; text-align: left;">
                <span class="tag">Control</span>:
                <span class="tag">Click + Drag = Rotate</span>
                <span class="tag">Ctrl + Drag = Translate</span>
                <span class="tag">Scroll Up/Down = Zoom In/Out</span>
              </div>
              <div class="query-container" style="padding: 10px; border-radius: 10px;">
                <button class="query-item" onclick="updateQuery('Query 1')">
                  <span class="query-dot"></span>
                  A blue and brown chair. It's located in front of a window and it's facing a wooden desk with a
                  computer
                  on it.
                </button>
                <button class="query-item" onclick="updateQuery('Query 2')">
                  <span class="query-dot"></span>
                  This door is blue and does not lead to a bathroom.
                </button>
                <button class="query-item" onclick="updateQuery('Query 3')">
                  <span class="query-dot"></span>
                  The door to the bathroom
                </button>
              </div>
              <!-- 点云和图像并排展示区域 -->
              <div class="columns" style="margin-top: -10px; display: flex; justify-content: space-between;">
                <!-- 使用 Bulma 的 is-half 类来确保每个 column 占据 50% 的宽度 -->
                <div class="column is-half" style="padding-right: 10px; ">
                  <!-- 左边是点云展示区域 -->
                  <p style="text-align: center; "><b>Interactive 3D Scene</b></p>

                  <div id="point-cloud"
                    style="width: 100%; height: 400px; border-radius: 10px; border: 1px solid #ccc; overflow: hidden;">
                    <!-- 点云将在这里渲染 -->
                  </div>
                </div>
                <div class="column is-half" style="padding-left: 10px;">
                  <!-- 右边是渲染图展示区域 -->
                  <p style="text-align: center;"><b>Query-Aligned Image<b></p>

                  <div
                    style="width: 100%; height: 400px; text-align: center; border-radius: 10px;border: 1px solid #ccc; ">
                    <img id="renderedImage" src='./seeground/0046_00-00.png' ;
                      style="width: 100%; height: 100%; object-fit: cover; border-radius: 10px;" />
                  </div>
                </div>
              </div>
              <hr>
            </div>


            <br/><br/>


            <div class="columns is-centered has-text-centered">
              <div class="column is-four-fifths">
                <h2 class="title is-3">
                  <span class="icon"><i class="fas fa-calculator"></i></span>&thinsp; Quantitative Results on ScanRefer
                </h2>
                
                    <div class="table-container">
                      <table class="table is-bordered is-striped is-hoverable">
                        <thead>
                          <tr>
                              <th rowspan="2">Method</th>
                              <th rowspan="2">Venue</th>
                              <th rowspan="2">Supervision</th>
                              <th rowspan="2">Agent</th>
                              <th colspan="2">Unique</th>
                              <th colspan="2">Multiple</th>
                              <th colspan="2">Overall</th>
                          </tr>
                          <tr>
                              <th>Acc@0.25</th>
                              <th>Acc@0.5</th>
                              <th>Acc@0.25</th>
                              <th>Acc@0.5</th>
                              <th>Acc@0.25</th>
                              <th>Acc@0.5</th>
                          </tr>
                      </thead>
                      <tbody>
                          <tr>
                              <td><a>ScanRefer</a></td>
                              <td>ECCV'20</td>
                              <td>Fully</td>
                              <td>-</td>
                              <td>67.6</td>
                              <td>46.2</td>
                              <td>32.1</td>
                              <td>21.3</td>
                              <td>39.0</td>
                              <td>26.1</td>
                          </tr>
                          <tr>
                              <td><a>InstanceRefer</a></td>
                              <td>ICCV'21</td>
                              <td>Fully</td>
                              <td>-</td>
                              <td>77.5</td>
                              <td>66.8</td>
                              <td>31.3</td>
                              <td>24.8</td>
                              <td>40.2</td>
                              <td>32.9</td>
                          </tr>
                          <tr>
                              <td><a>3DVG-Transformer</a></td>
                              <td>ICCV'21</td>
                              <td>Fully</td>
                              <td>-</td>
                              <td>77.2</td>
                              <td>58.5</td>
                              <td>38.4</td>
                              <td>28.7</td>
                              <td>45.9</td>
                              <td>34.5</td>
                          </tr>
                          <tr>
                              <td><a>BUTD-DETR</a></td>
                              <td>ECCV'22</td>
                              <td>Fully</td>
                              <td>-</td>
                              <td>84.2</td>
                              <td>66.3</td>
                              <td>46.6</td>
                              <td>35.1</td>
                              <td>52.2</td>
                              <td>39.8</td>
                          </tr>
                          <tr>
                              <td><a>EDA</a></td>
                              <td>CVPR'23</td>
                              <td>Fully</td>
                              <td>-</td>
                              <td>85.8</td>
                              <td>68.6</td>
                              <td>49.1</td>
                              <td>37.6</td>
                              <td>54.6</td>
                              <td>42.3</td>
                          </tr>
                          <tr>
                              <td><a>3D-VisTA</a></td>
                              <td>ICCV'23</td>
                              <td>Fully</td>
                              <td>-</td>
                              <td>81.6</td>
                              <td>75.1</td>
                              <td>43.7</td>
                              <td>39.1</td>
                              <td>50.6</td>
                              <td>45.8</td>
                          </tr>
                          <tr>
                              <td><a>G3-LQ</a></td>
                              <td>CVPR'24</td>
                              <td>Fully</td>
                              <td>-</td>
                              <td>88.6</td>
                              <td>73.3</td>
                              <td>50.2</td>
                              <td>39.7</td>
                              <td>56.0</td>
                              <td>44.7</td>
                          </tr>
                          <tr>
                              <td><a>MCLN</a></td>
                              <td>ECCV'24</td>
                              <td>Fully</td>
                              <td>-</td>
                              <td>86.9</td>
                              <td>72.7</td>
                              <td>52.0</td>
                              <td>40.8</td>
                              <td>57.2</td>
                              <td>45.7</td>
                          </tr>
                          <tr>
                              <td><a>ConcreteNet</a></td>
                              <td>ECCV'24</td>
                              <td>Fully</td>
                              <td>-</td>
                              <td>86.4</td>
                              <td>82.1</td>
                              <td>42.4</td>
                              <td>38.4</td>
                              <td>50.6</td>
                              <td>46.5</td>
                          </tr>
                          <tr>
                              <td><a>WS-3DVG</a></td>
                              <td>ICCV'23</td>
                              <td>Weakly</td>
                              <td>-</td>
                              <td>-</td>
                              <td>-</td>
                              <td>-</td>
                              <td>-</td>
                              <td>27.4</td>
                              <td>22.0</td>
                          </tr>
                          <tr>
                              <td><a>LERF</a></td>
                              <td>ICCV'23</td>
                              <td>Zero-Shot</td>
                              <td>CLIP</td>
                              <td>-</td>
                              <td>-</td>
                              <td>-</td>
                              <td>-</td>
                              <td>4.8</td>
                              <td>0.9</td>
                          </tr>
                          <tr>
                              <td><a>OpenScene</a></td>
                              <td>CVPR'23</td>
                              <td>Zero-Shot</td>
                              <td>CLIP</td>
                              <td>20.1</td>
                              <td>13.1</td>
                              <td>11.1</td>
                              <td>4.4</td>
                              <td>13.2</td>
                              <td>6.5</td>
                          </tr>
                          <tr>
                              <td><a>LLM-G</a></td>
                              <td>ICRA'24</td>
                              <td>Zero-Shot</td>
                              <td>GPT-3.5</td>
                              <td>-</td>
                              <td>-</td>
                              <td>-</td>
                              <td>-</td>
                              <td>14.3</td>
                              <td>4.7</td>
                          </tr>
                          <tr>
                              <td><a>LLM-G</a></td>
                              <td>ICRA'24</td>
                              <td>Zero-Shot</td>
                              <td>GPT-4 turbo</td>
                              <td>-</td>
                              <td>-</td>
                              <td>-</td>
                              <td>-</td>
                              <td>17.1</td>
                              <td>5.3</td>
                          </tr>
                          <tr>
                              <td><a>ZSVG3D</a></td>
                              <td>CVPR'24</td>
                              <td>Zero-Shot</td>
                              <td>GPT-4 turbo</td>
                              <td>63.8</td>
                              <td>58.4</td>
                              <td>27.7</td>
                              <td>24.6</td>
                              <td>36.4</td>
                              <td>32.7</td>
                          </tr>
                          <tr>
                              <td><b><span style="color: #FF8E26;"><b>See</b></span><span style="color: #01B1A0;"><b>Ground</b></span></b></td>
                              <td><b>Ours</b></td>
                              <td><b>Zero-Shot</b></td>
                              <td>Qwen2-VL-72b</td>
                              <td>75.7</td>
                              <td>68.9</td>
                              <td>34.0</td>
                              <td>30.0</td>
                              <td>44.1</td>
                              <td>39.4</td>
                          </tr>
                      </tbody>
                      </table>
                      <span>
                        <b>Table 1.</b> Evaluations of state-of-the-art 3DVG methods on ScanRefer validation set. 
                        Results are reported for "Unique" (scenes with a single target object) and "Multiple" (scenes with distractors of the same class) subsets, along with the overall performance.
                      </span>
                    </div>
              </div>
            </div>


          <hr><br/><br/><br/>



          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">
                    <span class="icon"><i class="fas fa-calculator"></i></span>&thinsp; Quantitative Results on Nr3D
                </h2>
                
                <div class="table-wrapper" style="display: flex; justify-content: center; align-items: center;">
                    <div class="table-container">
                        <table class="table is-bordered is-striped is-hoverable" style="margin: auto; text-align: center;">
                        <thead>
                        <tr>
                            <th>Method</th>
                            <th>Venue</th>
                            <th>Easy</th>
                            <th>Hard</th>
                            <th>Dependent</th>
                            <th>Independent</th>
                            <th>Overall</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td colspan="7"><strong>Supervision: Fully Supervised 3DVG</strong></td>
                        </tr>
                        <tr>
                            <td><a>ReferIt3DNet</a></td>
                            <td>ECCV'20</td>
                            <td>43.6</td>
                            <td>27.9</td>
                            <td>32.5</td>
                            <td>37.1</td>
                            <td>35.6</td>
                        </tr>
                        <tr>
                            <td><a>TGNN</a></td>
                            <td>AAAI'21</td>
                            <td>44.2</td>
                            <td>30.6</td>
                            <td>35.8</td>
                            <td>38.0</td>
                            <td>37.3</td>
                        </tr>
                        <tr>
                            <td><a>InstanceRefer</a></td>
                            <td>ICCV'21</td>
                            <td>46.0</td>
                            <td>31.8</td>
                            <td>34.5</td>
                            <td>41.9</td>
                            <td>38.8</td>
                        </tr>
                        <tr>
                            <td><a>3DVG-Transformer</a></td>
                            <td>ICCV'2</td>
                            <td>48.5</td>
                            <td>34.8</td>
                            <td>34.8</td>
                            <td>43.7</td>
                            <td>40.8</td>
                        </tr>
                        <tr>
                            <td><a>BUTD-DETR</a></td>
                            <td>ECCV'22</td>
                            <td>60.7</td>
                            <td>48.4</td>
                            <td>46.0</td>
                            <td>58.0</td>
                            <td>54.6</td>
                        </tr>
                        <tr>
                            <td colspan="7"><strong>Supervision: Weakly Supervised 3DVG</strong></td>
                        </tr>
                        <tr>
                            <td><a>WS-3DVG</a></td>
                            <td>ICCV'23</td>
                            <td>27.3</td>
                            <td>18.0</td>
                            <td>21.6</td>
                            <td>22.9</td>
                            <td>22.5</td>
                        </tr>
                        <tr>
                            <td colspan="7"><strong>Supervision: Zero-Shot 3DVG</strong></td>
                        </tr>
                        <tr>
                            <td><a>ZSVG3D</a></td>
                            <td>CVPR'24</td>
                            <td>46.5</td>
                            <td>31.7</td>
                            <td>36.8</td>
                            <td>40.0</td>
                            <td>39.0</td>
                        </tr>
                        <tr>
                            <td><b><span style="color: #FF8E26;"><b>See</b></span><span style="color: #01B1A0;"><b>Ground</b></span></b></td>
                            <td><b>Ours</b></td>
                            <td>54.5</td>
                            <td>38.3</td>
                            <td>42.3</td>
                            <td>48.2</td>
                            <td>46.1</td>
                        </tr>
                    </tbody>
                    </table>
                    <span>
                      <br/>
                      <b>Table 2.</b> Evaluations of state-of-the-art 3DVG methods on Nr3D validation set. 
                      Queries are labeled as "Easy" (one distractor) or "Hard" (multiple distractors), and as "View-Dependent" or "View-Independent" based on viewpoint requirements for grounding.
                    </span>
                  </div>
            </div><hr>
          </div>
  </section>



  <section class="section" style="margin-top: -50px;"></section>
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class=" column is-full-width has-text-centered">
        <h2 class="title is-3">
          <span class="icon"><i class="fa fa-puzzle-piece"></i></span>&thinsp; More Examples
        </h2>
      <img src="./static/images/more_examples.png" />
      <hr>
    </div>
  </div>
  </div>
  </section>

  <br/>
  

  <!-- 
-------------------------------------------------------------------------------------------------------- 
-->
  <section class="section" id="BibTeX" style="margin-top: -20px;">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre style="border-radius: 10px;"><code>@article{li2024seeground,
  title   = {SeeGround: See and Ground for Zero-Shot Open-Vocabulary 3D Visual Grounding},
  author  = {Rong Li and Shijie Li and Lingdong Kong and Xulei Yang and Junwei Liang},
  journal = {IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year    = {2025},
}</code></pre>
  <hr>
    </div>
  </section>





  <section class="section" style="margin-top: -20px;">
    <div class="container is-max-desktop">
      <!-- Concurrent Work. -->
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Related Links</h2>

          <div class="content has-text-justified">
            <p>
              There are some other excellent works that were introduced around the same time as ours:
            </p>
            <p>
              - 
              <a href="https://arxiv.org/abs/2410.13860">
                VLM-Grounder: A VLM Agent for Zero-Shot 3D Visual Grounding
              </a>
            </p>
            <p>
              - 
              <a href="https://arxiv.org/abs/2411.14594">
                Solving Zero-Shot 3D Visual Grounding as Constraint Satisfaction Problems
              </a>
            </p>
            <p>
              - 
              <a href="https://ieeexplore.ieee.org/document/10592798">
                ViewInfer3D: 3D Visual Grounding based on Embodied Viewpoint Inference
              </a>
            </p>

          </div>
        </div>
      </div>
      <!--/ Concurrent Work. -->

    </div>
  </section>



  <br/>





  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              We thank the <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> authors for their
              excellent templates, which we used as a basis for our site.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>
